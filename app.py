"""
Dashboard Streamlit Int√©gr√© - Projet Amazon Webscraping
ISSEA MDSMS2 - 2025/2026

Application compl√®te pour Cloud Run :
- Dashboard de visualisation temps r√©el
- Contr√¥le du scraping
- Historique et alertes
- Scraping automatis√© en background

Pour lancer : streamlit run app.py
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
from datetime import datetime, timedelta
import logging
import os
import threading
from apscheduler.schedulers.background import BackgroundScheduler

# Imports locaux
from database import get_db
from scraper import run_scraping_job
from alertes import run_alerte_job

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuration de la page
st.set_page_config(
    page_title="Amazon Analytics Dashboard - ISSEA",
    page_icon="üõí",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown("""
    <style>
    .main {
        padding: 0rem 1rem;
    }
    .stMetric {
        background-color: #f0f2f6;
        padding: 10px;
        border-radius: 5px;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding-left: 20px;
        padding-right: 20px;
    }
    </style>
    """, unsafe_allow_html=True)


# ===========================
# SCHEDULER BACKGROUND
# ===========================

@st.cache_resource
def init_scheduler():
    """
    Initialise le scheduler pour scraping automatique.

    ‚ö†Ô∏è IMPORTANT : Sur Cloud Run, utiliser Cloud Scheduler √† la place.
    Cette fonction est utile pour tests locaux uniquement.
    """
    # D√©sactiver sur Cloud Run (utiliser Cloud Scheduler √† la place)
    if os.getenv('K_SERVICE'):  # Variable d'environnement Cloud Run
        logger.info("üåê Cloud Run d√©tect√© - Scheduler d√©sactiv√© (utiliser Cloud Scheduler)")
        return None

    scheduler = BackgroundScheduler()

    # Configuration : Scraping quotidien √† 2h du matin
    scheduler.add_job(
        func=job_scraping_background,
        trigger='cron',
        hour=2,
        minute=0,
        id='scraping_quotidien'
    )

    # Configuration : Alertes quotidiennes √† 8h du matin
    scheduler.add_job(
        func=job_alertes_background,
        trigger='cron',
        hour=8,
        minute=0,
        id='alertes_quotidiennes'
    )

    scheduler.start()
    logger.info("‚úÖ Scheduler initialis√© - Scraping quotidien √† 2h00")

    return scheduler


def job_scraping_background():
    """Job de scraping en background"""
    logger.info("ü§ñ Lancement scraping automatique...")
    try:
        result = run_scraping_job(mots_cles="laptop", nb_produits=100, max_pages=5)
        logger.info(f"‚úÖ Scraping automatique termin√© : {result}")
    except Exception as e:
        logger.error(f"‚ùå Erreur scraping automatique : {e}")


def job_alertes_background():
    """Job d'alertes en background"""
    logger.info("üîî Lancement alertes automatiques...")
    try:
        result = run_alerte_job()
        logger.info(f"‚úÖ Alertes automatiques termin√©es : {result}")
    except Exception as e:
        logger.error(f"‚ùå Erreur alertes automatiques : {e}")


# Initialiser le scheduler (d√©sactiv√© sur Cloud Run)
scheduler = init_scheduler()


# ===========================
# FONCTIONS UTILITAIRES
# ===========================

@st.cache_data(ttl=300)  # Cache 5 minutes
def load_data():
    """Charge les donn√©es depuis la base de donn√©es"""
    try:
        db = get_db()
        df = db.get_produits_recents(limit=1000)

        # Conversion des types
        df['Prix'] = pd.to_numeric(df['prix'], errors='coerce')
        df['Vote'] = pd.to_numeric(df['vote'], errors='coerce')

        return df
    except Exception as e:
        st.error(f"‚ùå Erreur chargement donn√©es : {e}")
        return pd.DataFrame()


@st.cache_data(ttl=300)
def load_alertes():
    """Charge les alertes r√©centes"""
    try:
        db = get_db()
        return db.get_alertes_recentes(limit=50)
    except Exception as e:
        st.error(f"‚ùå Erreur chargement alertes : {e}")
        return pd.DataFrame()


@st.cache_data(ttl=300)
def load_stats():
    """Charge les statistiques globales"""
    try:
        db = get_db()
        return db.get_statistiques_scraping()
    except Exception as e:
        st.error(f"‚ùå Erreur chargement stats : {e}")
        return {}


# ===========================
# EN-T√äTE
# ===========================

st.title("üõí Amazon Analytics Dashboard")
st.markdown("### Analyse en temps r√©el des produits scrap√©s - ISSEA MDSMS2")
st.markdown("---")


# ===========================
# TABS PRINCIPAUX
# ===========================

tab1, tab2, tab3, tab4 = st.tabs([
    "üìä Visualisations",
    "ü§ñ Contr√¥le Scraping",
    "üîî Alertes & Historique",
    "üìà Statistiques Avanc√©es"
])


# ===========================
# TAB 1 : VISUALISATIONS
# ===========================

with tab1:
    # Chargement des donn√©es
    df = load_data()

    if df.empty:
        st.warning("‚ö†Ô∏è Aucune donn√©e disponible. Lancez un scraping depuis l'onglet 'Contr√¥le Scraping'.")
    else:
        # Sidebar - Filtres
        with st.sidebar:
            st.header("üîç Filtres")

            # Filtre prix
            st.subheader("Prix (USD)")
            prix_valides = df['Prix'].dropna()
            if len(prix_valides) > 0:
                prix_min = int(prix_valides.min())
                prix_max = int(prix_valides.max())
                prix_range = st.slider(
                    "Fourchette de prix",
                    min_value=prix_min,
                    max_value=prix_max,
                    value=(prix_min, prix_max),
                    step=10
                )
            else:
                prix_range = (0, 0)

            # Filtre vote
            st.subheader("Note minimale")
            vote_valides = df['Vote'].dropna()
            if len(vote_valides) > 0:
                vote_min = st.slider(
                    "Note minimale (√©toiles)",
                    min_value=0.0,
                    max_value=5.0,
                    value=0.0,
                    step=0.5
                )
            else:
                vote_min = 0.0

        # Appliquer les filtres
        df_filtered = df.copy()
        if len(prix_valides) > 0:
            df_filtered = df_filtered[
                (df_filtered['Prix'].notna()) &
                (df_filtered['Prix'].between(prix_range[0], prix_range[1]))
            ]
        if len(vote_valides) > 0:
            df_filtered = df_filtered[
                (df_filtered['Vote'].notna()) &
                (df_filtered['Vote'] >= vote_min)
            ]

        st.sidebar.markdown("---")
        st.sidebar.info(f"üìä **{len(df_filtered)}** produits affich√©s sur **{len(df)}** au total")

        # M√©triques principales
        st.header("üìä M√©triques Cl√©s")
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                label="Produits Total",
                value=f"{len(df_filtered):,}",
                delta=f"{len(df_filtered) - len(df)} filtr√©s" if len(df_filtered) != len(df) else "Tous"
            )

        with col2:
            prix_moy = df_filtered['Prix'].mean()
            if pd.notna(prix_moy):
                st.metric(label="Prix Moyen", value=f"${prix_moy:,.2f}")
            else:
                st.metric(label="Prix Moyen", value="N/A")

        with col3:
            vote_moy = df_filtered['Vote'].mean()
            if pd.notna(vote_moy):
                st.metric(label="Note Moyenne", value=f"{vote_moy:.2f}/5.0")
            else:
                st.metric(label="Note Moyenne", value="N/A")

        with col4:
            prix_median = df_filtered['Prix'].median()
            if pd.notna(prix_median):
                st.metric(label="Prix M√©dian", value=f"${prix_median:,.2f}")
            else:
                st.metric(label="Prix M√©dian", value="N/A")

        st.markdown("---")

        # Graphiques principaux
        col_left, col_right = st.columns(2)

        with col_left:
            st.subheader("üìà Distribution des Prix")
            df_prix = df_filtered[df_filtered['Prix'].notna()]
            if len(df_prix) > 0:
                fig_hist = px.histogram(
                    df_prix,
                    x='Prix',
                    nbins=30,
                    title="Distribution des prix",
                    labels={'Prix': 'Prix (USD)', 'count': 'Nombre de produits'},
                    color_discrete_sequence=['#636EFA']
                )
                fig_hist.update_layout(showlegend=False, height=400)
                st.plotly_chart(fig_hist, use_container_width=True)
            else:
                st.warning("Aucune donn√©e de prix disponible")

        with col_right:
            st.subheader("‚≠ê Distribution des Notes")
            df_vote = df_filtered[df_filtered['Vote'].notna()]
            if len(df_vote) > 0:
                fig_vote = px.histogram(
                    df_vote,
                    x='Vote',
                    nbins=20,
                    title="Distribution des notes",
                    labels={'Vote': 'Note (√©toiles)', 'count': 'Nombre de produits'},
                    color_discrete_sequence=['#EF553B']
                )
                fig_vote.update_layout(showlegend=False, height=400)
                st.plotly_chart(fig_vote, use_container_width=True)
            else:
                st.warning("Aucune donn√©e de note disponible")

        # Scatter plot Prix vs Vote
        st.subheader("üí∞ Relation Prix - Note")
        df_complet = df_filtered[(df_filtered['Prix'].notna()) & (df_filtered['Vote'].notna())]
        if len(df_complet) > 0:
            fig_scatter = px.scatter(
                df_complet,
                x='Vote',
                y='Prix',
                hover_data=['titre'],
                title="Prix en fonction de la note",
                labels={'Vote': 'Note (√©toiles)', 'Prix': 'Prix (USD)'},
                color='Vote',
                color_continuous_scale='Viridis'
            )

            # Ligne de tendance
            if len(df_complet) > 1:
                z = np.polyfit(df_complet['Vote'], df_complet['Prix'], 1)
                p = np.poly1d(z)
                x_line = np.linspace(df_complet['Vote'].min(), df_complet['Vote'].max(), 100)
                fig_scatter.add_trace(
                    go.Scatter(
                        x=x_line,
                        y=p(x_line),
                        mode='lines',
                        name='Tendance',
                        line=dict(color='red', dash='dash')
                    )
                )

                # Corr√©lation
                correlation = df_complet['Prix'].corr(df_complet['Vote'])
                st.info(f"üìà Corr√©lation Prix-Note: **{correlation:.3f}**")

            fig_scatter.update_layout(height=500)
            st.plotly_chart(fig_scatter, use_container_width=True)
        else:
            st.warning("Pas assez de donn√©es pour afficher la corr√©lation")


# ===========================
# TAB 2 : CONTR√îLE SCRAPING
# ===========================

with tab2:
    st.header("ü§ñ Contr√¥le du Scraping")

    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("Lancer un Scraping Manuel")

        with st.form("scraping_form"):
            mots_cles = st.text_input("Mots-cl√©s de recherche", value="laptop")
            nb_produits = st.number_input("Nombre minimum de produits", min_value=10, max_value=500, value=100)
            max_pages = st.number_input("Pages maximum √† scraper", min_value=1, max_value=20, value=5)

            submit_button = st.form_submit_button("üöÄ Lancer le Scraping")

            if submit_button:
                with st.spinner(f"Scraping en cours de '{mots_cles}'..."):
                    try:
                        result = run_scraping_job(mots_cles=mots_cles, nb_produits=nb_produits, max_pages=max_pages)

                        if result['status'] == 'SUCCESS':
                            st.success(f"‚úÖ Scraping termin√© avec succ√®s !")
                            st.metric("Produits scrap√©s", result['nb_produits'])
                            st.metric("Nouveaux produits", result['nouveaux'])
                            st.metric("Mis √† jour", result['mises_a_jour'])
                            st.metric("Dur√©e (secondes)", f"{result['duree']:.1f}s")

                            # Rafra√Æchir le cache
                            st.cache_data.clear()
                            st.rerun()
                        else:
                            st.error(f"‚ùå Erreur : {result.get('error', 'Erreur inconnue')}")

                    except Exception as e:
                        st.error(f"‚ùå Erreur durant le scraping : {e}")

    with col2:
        st.subheader("Configuration")

        stats = load_stats()

        if stats:
            st.metric("Total Produits en BDD", stats.get('total_produits', 0))
            st.metric("Total Scrapings", stats.get('total_scrapings', 0))

            if stats.get('dernier_scraping'):
                st.info(f"**Dernier scraping :**\n{stats['dernier_scraping']}")

        st.markdown("---")

        # Informations sur le scheduler
        if scheduler:
            st.success("‚úÖ Scheduler actif")
            st.info("üìÖ Scraping quotidien √† 2h00\nüîî Alertes quotidiennes √† 8h00")
        else:
            st.warning("‚ö†Ô∏è Scheduler d√©sactiv√© (Cloud Run)")
            st.info("Utilisez Cloud Scheduler pour automatisation")


# ===========================
# TAB 3 : ALERTES
# ===========================

with tab3:
    st.header("üîî Alertes & Historique")

    df_alertes = load_alertes()

    if df_alertes.empty:
        st.info("üì≠ Aucune alerte pour le moment.")
    else:
        st.subheader(f"üì¨ {len(df_alertes)} Alerte(s) R√©cente(s)")

        # Tableau des alertes
        df_alertes_display = df_alertes.copy()
        df_alertes_display['ancien_prix'] = df_alertes_display['ancien_prix'].apply(
            lambda x: f"${x:.2f}" if pd.notna(x) else "N/A"
        )
        df_alertes_display['nouveau_prix'] = df_alertes_display['nouveau_prix'].apply(
            lambda x: f"${x:.2f}" if pd.notna(x) else "N/A"
        )

        st.dataframe(df_alertes_display, use_container_width=True, hide_index=True)

    st.markdown("---")

    # Bouton pour d√©clencher alertes manuellement
    if st.button("üîî V√©rifier et Envoyer Alertes Maintenant"):
        with st.spinner("V√©rification des alertes..."):
            try:
                result = run_alerte_job()
                if result['status'] == 'SUCCESS':
                    st.success("‚úÖ Alertes v√©rifi√©es et envoy√©es !")
                else:
                    st.error(f"‚ùå Erreur : {result.get('error')}")
            except Exception as e:
                st.error(f"‚ùå Erreur : {e}")


# ===========================
# TAB 4 : STATISTIQUES AVANC√âES
# ===========================

with tab4:
    st.header("üìà Statistiques Avanc√©es")

    df = load_data()

    if not df.empty:
        # Top 10 produits
        col_top1, col_top2 = st.columns(2)

        with col_top1:
            st.subheader("üèÜ Top 10 - Mieux Not√©s")
            top_votes = df.nlargest(10, 'Vote')[['titre', 'Prix', 'Vote']]
            if len(top_votes) > 0:
                top_votes_display = top_votes.copy()
                top_votes_display['Prix'] = top_votes_display['Prix'].apply(
                    lambda x: f"${x:,.2f}" if pd.notna(x) else "N/A"
                )
                top_votes_display['Vote'] = top_votes_display['Vote'].apply(
                    lambda x: f"{x:.1f}/5" if pd.notna(x) else "N/A"
                )
                st.dataframe(top_votes_display, use_container_width=True, hide_index=True)

        with col_top2:
            st.subheader("üíé Top 10 - Plus Chers")
            top_prix = df.nlargest(10, 'Prix')[['titre', 'Prix', 'Vote']]
            if len(top_prix) > 0:
                top_prix_display = top_prix.copy()
                top_prix_display['Prix'] = top_prix_display['Prix'].apply(
                    lambda x: f"${x:,.2f}" if pd.notna(x) else "N/A"
                )
                top_prix_display['Vote'] = top_prix_display['Vote'].apply(
                    lambda x: f"{x:.1f}/5" if pd.notna(x) else "N/A"
                )
                st.dataframe(top_prix_display, use_container_width=True, hide_index=True)

        st.markdown("---")

        # Statistiques d√©taill√©es
        with st.expander("üìä Statistiques D√©taill√©es"):
            col_stat1, col_stat2 = st.columns(2)

            with col_stat1:
                st.markdown("#### Prix")
                prix_stats = df['Prix'].describe()
                st.dataframe(prix_stats, use_container_width=True)

            with col_stat2:
                st.markdown("#### Notes")
                vote_stats = df['Vote'].describe()
                st.dataframe(vote_stats, use_container_width=True)


# ===========================
# FOOTER
# ===========================

st.markdown("---")
st.markdown(
    f"""
    <div style='text-align: center; color: gray;'>
    <p>Dashboard cr√©√© avec ‚ù§Ô∏è par ISSEA MDSMS2 | Projet Amazon Webscraping</p>
    <p>Derni√®re mise √† jour: {datetime.now().strftime('%d/%m/%Y %H:%M')}</p>
    <p>üåê D√©ploy√© sur Google Cloud Run</p>
    </div>
    """,
    unsafe_allow_html=True
)
