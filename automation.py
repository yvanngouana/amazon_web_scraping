"""
Script d'Automatisation - Scraping Amazon
ISSEA MDSMS2 - 2025/2026

Ce script permet d'automatiser le scraping Amazon √† intervalles r√©guliers.

Usage:
    python automation.py

Le script tourne en continu et ex√©cute le scraping selon la planification d√©finie.
"""

import schedule
import time
from datetime import datetime
import pandas as pd
import sys
import os

# Ajouter le r√©pertoire courant au path pour les imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Configuration
MOTS_CLES = "laptop"  # Mots-cl√©s √† scraper
NB_PRODUITS_MIN = 100  # Nombre minimum de produits par scraping
MAX_PAGES = 5  # Nombre maximum de pages √† scraper
DOSSIER_SAUVEGARDE = "scraping_auto"  # Dossier pour sauvegarder les r√©sultats

# Cr√©er le dossier de sauvegarde s'il n'existe pas
os.makedirs(DOSSIER_SAUVEGARDE, exist_ok=True)


def log_message(message):
    """Affiche un message avec timestamp"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] {message}")


def job_scraping():
    """
    Fonction principale de scraping automatis√©.

    Cette fonction :
    1. Lance le scraping
    2. Sauvegarde les donn√©es avec timestamp
    3. G√©n√®re un rapport de synth√®se
    """
    log_message("=" * 80)
    log_message("üöÄ D√âBUT DU SCRAPING AUTOMATIS√â")
    log_message("=" * 80)

    try:
        # Import de la fonction de scraping
        # Note: Vous devrez adapter cet import selon votre structure
        log_message("üì¶ Import des modules de scraping...")

        # OPTION 1: Si vous avez extrait les fonctions dans un fichier s√©par√©
        # from scraper import scraper_amazon

        # OPTION 2: Si vous utilisez le notebook, utilisez cette approche
        log_message("‚ö†Ô∏è  Pour utiliser ce script, extrayez la fonction scraper_amazon du notebook")
        log_message("‚ö†Ô∏è  et placez-la dans un fichier scraper.py")

        # Exemple de code √† mettre dans scraper.py :
        """
        from selenium import webdriver
        # ... (tout le code de setup_driver, extraire_info_produit, etc.)

        def scraper_amazon(mots_cles, nb_min_produits=300, max_pages=15):
            # ... (votre fonction de scraping)
            pass
        """

        # Pour la d√©mo, on simule un scraping
        log_message(f"üîç Scraping des produits '{MOTS_CLES}'...")
        log_message(f"   Objectif: {NB_PRODUITS_MIN} produits minimum")
        log_message(f"   Pages max: {MAX_PAGES}")

        # Simuler un d√©lai de scraping
        time.sleep(2)

        # Dans un cas r√©el, vous appelleriez :
        # df = scraper_amazon(MOTS_CLES, nb_min_produits=NB_PRODUITS_MIN, max_pages=MAX_PAGES)

        # Pour la d√©mo, cr√©ons un DataFrame factice
        log_message("‚úÖ Scraping termin√© (d√©mo)")

        # G√©n√©rer le nom de fichier avec timestamp
        timestamp_fichier = datetime.now().strftime("%Y%m%d_%H%M%S")
        fichier_csv = os.path.join(DOSSIER_SAUVEGARDE, f"bd_{timestamp_fichier}.csv")

        # Dans un cas r√©el, vous sauvegarderiez :
        # df.to_csv(fichier_csv, index=False, encoding='utf-8-sig')
        # log_message(f"üíæ Donn√©es sauvegard√©es: {fichier_csv}")
        # log_message(f"   Nombre de produits: {len(df)}")

        log_message(f"üíæ Fichier de sauvegarde pr√©vu: {fichier_csv}")

        # G√©n√©rer un rapport de synth√®se
        generer_rapport_synthese()

        log_message("=" * 80)
        log_message("‚úÖ SCRAPING AUTOMATIS√â TERMIN√â AVEC SUCC√àS")
        log_message("=" * 80)

    except Exception as e:
        log_message(f"‚ùå ERREUR durant le scraping: {e}")
        log_message("=" * 80)
        # En production, vous pourriez envoyer un email d'alerte ici


def generer_rapport_synthese():
    """
    G√©n√®re un rapport de synth√®se des scrapings effectu√©s.
    """
    log_message("üìä G√©n√©ration du rapport de synth√®se...")

    # Lister tous les fichiers CSV dans le dossier
    fichiers = [f for f in os.listdir(DOSSIER_SAUVEGARDE) if f.endswith('.csv')]

    if not fichiers:
        log_message("   Aucun fichier de scraping trouv√©")
        return

    log_message(f"   Nombre de scrapings effectu√©s: {len(fichiers)}")

    # Analyser les fichiers (dans un cas r√©el)
    # for fichier in fichiers:
    #     df = pd.read_csv(os.path.join(DOSSIER_SAUVEGARDE, fichier))
    #     log_message(f"   - {fichier}: {len(df)} produits")

    # Cr√©er un rapport consolid√©
    rapport_fichier = os.path.join(DOSSIER_SAUVEGARDE, "rapport_synthese.txt")
    with open(rapport_fichier, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("RAPPORT DE SYNTH√àSE - SCRAPING AMAZON AUTOMATIS√â\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"Date du rapport: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Nombre de scrapings: {len(fichiers)}\n\n")
        f.write("Fichiers g√©n√©r√©s:\n")
        for fichier in sorted(fichiers):
            f.write(f"  - {fichier}\n")

    log_message(f"   Rapport sauvegard√©: {rapport_fichier}")


def envoyer_alerte_email(sujet, message):
    """
    Envoie une alerte par email (√† impl√©menter).

    Args:
        sujet: Sujet de l'email
        message: Corps du message
    """
    # √Ä impl√©menter avec smtplib si n√©cessaire
    log_message(f"üìß Alerte email: {sujet}")
    log_message(f"   Message: {message}")


def afficher_configuration():
    """Affiche la configuration actuelle"""
    log_message("=" * 80)
    log_message("‚öôÔ∏è  CONFIGURATION DU BOT DE SCRAPING")
    log_message("=" * 80)
    log_message(f"Mots-cl√©s: {MOTS_CLES}")
    log_message(f"Produits minimum: {NB_PRODUITS_MIN}")
    log_message(f"Pages maximum: {MAX_PAGES}")
    log_message(f"Dossier de sauvegarde: {DOSSIER_SAUVEGARDE}")
    log_message("=" * 80)


def main():
    """
    Fonction principale - Configure et lance le scheduler.
    """
    afficher_configuration()

    log_message("\nü§ñ BOT DE SCRAPING AMAZON D√âMARR√â")
    log_message("=" * 80)

    # OPTION 1: Planifier tous les jours √† une heure fixe
    schedule.every().day.at("08:00").do(job_scraping)
    log_message("üìÖ Planification: Tous les jours √† 08:00")

    # OPTION 2: Planifier toutes les X heures (d√©commentez si n√©cessaire)
    # schedule.every(6).hours.do(job_scraping)
    # log_message("üìÖ Planification: Toutes les 6 heures")

    # OPTION 3: Planifier toutes les X minutes (pour tests)
    # schedule.every(30).minutes.do(job_scraping)
    # log_message("üìÖ Planification: Toutes les 30 minutes")

    # Pour tester imm√©diatement, d√©commentez cette ligne :
    # log_message("üß™ Ex√©cution imm√©diate pour test...")
    # job_scraping()

    log_message("\n‚è∞ En attente de la prochaine ex√©cution...")
    log_message("   (Appuyez sur Ctrl+C pour arr√™ter)\n")

    # Boucle principale
    try:
        while True:
            schedule.run_pending()
            time.sleep(60)  # V√©rifier toutes les minutes
    except KeyboardInterrupt:
        log_message("\n" + "=" * 80)
        log_message("üõë BOT DE SCRAPING ARR√äT√â PAR L'UTILISATEUR")
        log_message("=" * 80)


if __name__ == "__main__":
    main()
